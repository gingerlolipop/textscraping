{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping voting information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Objective\n",
    "This notebook is about scraping text from https://petition.parliament.uk/petitions.\n",
    "\n",
    "In this notebook, I scraped information of the \n",
    "1. MP names for each constituency\n",
    "2. Numbers of vote in each constituency\n",
    "3. Information from 1. and 2. of each petition on the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "This notebook contains three sections indicating the three steps towrds the objective of this notebook\n",
    "\n",
    "1. Get a list of numbers that locates special urls for petitions\n",
    "\n",
    "2. Get the html for each petition\n",
    "\n",
    "3. Parse the html data; Clean and save the data to csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get a list of numbers that locates special urls for petitions\n",
    "The website provides a csv file stating each petition name and url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/iGingerMac/Google Drive/2019 Python/Web Scraping\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/iGingerMac/Google Drive/2019 Python/Web Scraping/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1 = pd.read_csv('filted_petitions.csv')\n",
    "#Only the petitions that are open or closed have voting information\n",
    "#Petitions that are rejected(not meeting petition standards) did not have voting information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\n",
    "Why was this petition rejected?\n",
    "\n",
    "It’s not clear what the petition is asking the UK Government or Parliament to do.\n",
    "\n",
    "Petitions need to call on the Government or Parliament to take a specific action.\n",
    "\n",
    "You could start a new petition explaining clearly what you would like the Government or Parliament to do. For example, you could ask the UK Parliament to change the law to require consultation of local communities before train services are reduced or stations are closed.\n",
    "\n",
    "We only reject petitions that don’t meet the petition standards.\"\n",
    "\n",
    "-----https://petition.parliament.uk/petitions/200010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the url for each petition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1['url_j']=csv1['url'].add('.json')\n",
    "csv1['number']=csv1['URL'].str.strip().str[-6:]\n",
    "\n",
    "#After browsing several .json webpages, I found that the url for each petition have the same formats. They are the \n",
    "#original url plus \".json\". Thus, I created a column of 'url_j' for the json data by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1.to_csv('/Users/iGingerMac/Google Drive/2019 Python/Web Scraping/csv/layer1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Iterate over rows of `url_j` to get `response obj` -> `str` -> `json` -> `dataframe` -> `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "for index, row in csv1.iterrows():\n",
    "    page=requests.Session().get(csv1['url_j'].iloc[index]).text\n",
    "    useless,mp=page.split('\"signatures_by_constituency\":')\n",
    "    mp,useless=mp.split('}}}')\n",
    "\n",
    "\n",
    "    m=json.dumps(mp)\n",
    "    data_i = pd.read_json(eval(m))\n",
    "    data_i.to_csv('/Users/iGingerMac/Google Drive/2019 Python/Web Scraping/csv/petition_'+csv1['number'].iloc[index]+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
